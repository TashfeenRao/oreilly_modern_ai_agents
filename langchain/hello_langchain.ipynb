{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda531c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d775710",
   "metadata": {},
   "source": [
    "### Setup / Grabbing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de522bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded docs and stored in chroma vector store\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://ai-office-hours.beehiiv.com/p/beyond-benchmarks\",\n",
    "    \"https://ai-office-hours.beehiiv.com/p/evaluating-ai-agent-tool-selection\",\n",
    "    \"https://ai-office-hours.beehiiv.com/p/re-ranking-rag\",\n",
    "    \"https://ai-office-hours.beehiiv.com/p/quantizing-llms-llama-3\",\n",
    "    \"https://ai-office-hours.beehiiv.com/p/llm-probing\"\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [doc for sublist in docs for doc in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs_list)\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    collection_name=\"rag-chroma\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "print(\"loaded docs and stored in chroma vector store\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a way to run tests automatically, there is no reas https://ai-office-hours.beehiiv.com/p/re-ranking-rag\n",
      "a way to run tests automatically, there is no reas https://ai-office-hours.beehiiv.com/p/re-ranking-rag\n",
      "a way to run tests automatically, there is no reas https://ai-office-hours.beehiiv.com/p/re-ranking-rag\n",
      "a way to run tests automatically, there is no reas https://ai-office-hours.beehiiv.com/p/re-ranking-rag\n"
     ]
    }
   ],
   "source": [
    "question = \"tell me about ra ranking\"\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:50], doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ac078",
   "metadata": {},
   "source": [
    "### Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a51d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary score: no\n",
      "page content: a way to run tests automatically, there is no reas\n",
      "\n",
      "Document Source: https://ai-office-hours.beehiiv.com/p/re-ranking-rag\n",
      "binary score: no\n",
      "page content: a way to run tests automatically, there is no reas\n",
      "\n",
      "Document Source: https://ai-office-hours.beehiiv.com/p/re-ranking-rag\n",
      "binary score: no\n",
      "page content: a way to run tests automatically, there is no reas\n",
      "\n",
      "Document Source: https://ai-office-hours.beehiiv.com/p/re-ranking-rag\n",
      "binary score: no\n",
      "page content: a way to run tests automatically, there is no reas\n",
      "\n",
      "Document Source: https://ai-office-hours.beehiiv.com/p/re-ranking-rag\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(description=\"A binary score of yes or no indicating if the document answers the question.\")\n",
    "    \n",
    "    \n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "system = \"\"\"Give a binary score of 'yes' or 'no' indicating if the document answers the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"user\", \"Question: {question}\\n\\n Document: {document}\\n\")\n",
    "])\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "for doc in docs:\n",
    "    result = retrieval_grader.invoke({\n",
    "        \"question\": question,\n",
    "        \"document\": doc.page_content\n",
    "    })\n",
    "    print(f\"binary score: {result.binary_score}\")\n",
    "    print(f\"page content: {doc.page_content[:50]}\\n\")\n",
    "    print(f\"Document Source: {doc.metadata['source']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b96e31",
   "metadata": {},
   "source": [
    "### Generate Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ab9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.SystemMessagePromptTemplate'>\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "----\n",
      "<class 'langchain_core.prompts.chat.HumanMessagePromptTemplate'>\n",
      "Question: {question}\n",
      "\n",
      "Context: {context}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "for message in prompt.messages:\n",
    "    print(type(message))\n",
    "    print(message.prompt.template)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183f101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer:\n",
      "RA ranking, or re-ranking in the context of Retrieval-Augmented Generation (RAG) systems, refers to the process of reordering retrieved documents or passages to improve retrieval accuracy before passing them to the generation model. This is typically done by testing different re-rankers to see if they provide a net benefit to the system's performance. The goal is to ensure that the most relevant information is prioritized for the generative model to use.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4.1\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(\"Generated Answer:\")\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5cd619",
   "metadata": {},
   "source": [
    "### Question Re-write / The corrective Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Question:\n",
      "What is the RA ranking and how is it determined?\n"
     ]
    }
   ],
   "source": [
    "bigger_llm = ChatOpenAI(model_name=\"gpt-4.1\", temperature=0.1)\n",
    "\n",
    "system = \"\"\"You are a question re-writer that converts an input question to a better version that is optimized \\n\n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "re_writer_chain = re_write_prompt | bigger_llm | StrOutputParser()\n",
    "improved_question = re_writer_chain.invoke({\"question\": question})\n",
    "print(\"Improved Question:\")\n",
    "print(improved_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad686219",
   "metadata": {},
   "source": [
    "### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \n",
    "    questions: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    times_transformed: int\n",
    "    web_search: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec16714",
   "metadata": {},
   "source": [
    "### The Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81b572d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_state(state):\n",
    "    \n",
    "    print(\"---- SET STATE ----\")\n",
    "    \n",
    "    return {\"times_transformed\": 0}\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    print(\"state\", state)\n",
    "    \n",
    "    print(\"---- RETRIEVE ----\")\n",
    "    question = state[\"questions\"]\n",
    "    docs = retriever.invoke(question)\n",
    "    return {\"documents\": docs}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    print(\"state\", state)\n",
    "    \n",
    "    print(\"---- GENERATE ----\")\n",
    "    context = state[\"documents\"]\n",
    "    question = state[\"questions\"]\n",
    "    generation = rag_chain.invoke({\"context\": format_docs(context), \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    print(\"state\", state)\n",
    "    \n",
    "    print(\"---- TRANSFORM QUERY ----\")\n",
    "    question = state[\"questions\"]\n",
    "    times_transformed = state[\"times_transformed\"]\n",
    "    times_transformed += 1\n",
    "    print(\"updated times transformed:\", times_transformed)\n",
    "    improved_question = re_writer_chain.invoke({\"question\": question})\n",
    "    print(\"improved question:\", improved_question)\n",
    "    return {\"questions\": improved_question, \"times_transformed\": times_transformed}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    print(\"state\", state)\n",
    "\n",
    "    print(\"---- GRADE DOCUMENTS ----\")\n",
    "    question = state[\"questions\"]\n",
    "    docs = state[\"documents\"]\n",
    "    graded_docs = []\n",
    "    web_search = \"No\"\n",
    "    for doc in docs:\n",
    "        result = retrieval_grader.invoke({\n",
    "            \"question\": question,\n",
    "            \"document\": doc.page_content\n",
    "        })\n",
    "        grade= result.binary_score\n",
    "        print(doc.metadata['source'] ,f'Grade: {grade}')\n",
    "\n",
    "        if grade == 'yes':\n",
    "            graded_docs.append(doc)\n",
    "\n",
    "    if not graded_docs:\n",
    "        print(\"No relevant documents found.\")\n",
    "        web_search = \"Yes\"\n",
    "    return {\"documents\": graded_docs, \"web_search\": web_search}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc4923",
   "metadata": {},
   "source": [
    "### The Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40450773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    print(\"state\", state)\n",
    "    \n",
    "    print(\"---- DECIDE TO GENERATE ----\")\n",
    "    web_search = state[\"web_search\"]\n",
    "    if web_search == \"Yes\":\n",
    "        print(\"time transformed:\", state[\"times_transformed\"])\n",
    "        if state[\"times_transformed\"] >= 2:\n",
    "            return \"should_generate\"\n",
    "        \n",
    "        print(\"---Decicion: ALL documents are not relevant, need to transform query---\")\n",
    "        \n",
    "        return \"should_transform_query\"\n",
    "    \n",
    "    else:\n",
    "        print(\"---Decision: Some documents are relevant, proceed to generate---\")\n",
    "        return \"should_generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f1af1",
   "metadata": {},
   "source": [
    "### Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00059501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"set_state\", set_state)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "\n",
    "#build the graph\n",
    "\n",
    "workflow.add_edge(START, \"set_state\")\n",
    "workflow.add_edge(\"set_state\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"should_transform_query\": \"transform_query\",\n",
    "        \"should_generate\": \"generate\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e68e93",
   "metadata": {},
   "source": [
    "### Running the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7caa300f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- SET STATE ----\n",
      "Node 'set_state' output:\n",
      "Final Output:\n",
      "state {'questions': 'What on earth is few shot learning?', 'times_transformed': 0}\n",
      "---- RETRIEVE ----\n",
      "Node 'retrieve' output:\n",
      "Final Output:\n",
      "state {'questions': 'What on earth is few shot learning?', 'documents': [Document(id='95640b43-35fb-4553-9c66-07d97ba79cd3', metadata={'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.', 'language': 'en', 'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'title': 'Probing LLMs for a World Model'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='1533ff1b-3cbb-4fbc-bd8d-abfa0e6305c6', metadata={'title': 'Probing LLMs for a World Model', 'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'language': 'en', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='121d9e85-0109-44ef-9976-b30e2df23688', metadata={'title': 'Probing LLMs for a World Model', 'language': 'en', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.', 'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='8539c230-32a2-4a01-b664-381c88574df0', metadata={'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'language': 'en', 'title': 'Probing LLMs for a World Model', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in')], 'times_transformed': 0}\n",
      "---- GRADE DOCUMENTS ----\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "No relevant documents found.\n",
      "state {'documents': [], 'web_search': 'Yes', 'questions': 'What on earth is few shot learning?', 'times_transformed': 0}\n",
      "---- DECIDE TO GENERATE ----\n",
      "time transformed: 0\n",
      "---Decicion: ALL documents are not relevant, need to transform query---\n",
      "Node 'grade_documents' output:\n",
      "Final Output:\n",
      "state {'questions': 'What on earth is few shot learning?', 'documents': [], 'times_transformed': 0, 'web_search': 'Yes'}\n",
      "---- TRANSFORM QUERY ----\n",
      "updated times transformed: 1\n",
      "improved question: What is few-shot learning in machine learning, and how does it work?\n",
      "Node 'transform_query' output:\n",
      "Final Output:\n",
      "state {'questions': 'What is few-shot learning in machine learning, and how does it work?', 'documents': [], 'times_transformed': 1, 'web_search': 'Yes'}\n",
      "---- RETRIEVE ----\n",
      "Node 'retrieve' output:\n",
      "Final Output:\n",
      "state {'questions': 'What is few-shot learning in machine learning, and how does it work?', 'documents': [Document(id='95640b43-35fb-4553-9c66-07d97ba79cd3', metadata={'language': 'en', 'title': 'Probing LLMs for a World Model', 'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='1533ff1b-3cbb-4fbc-bd8d-abfa0e6305c6', metadata={'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.', 'language': 'en', 'title': 'Probing LLMs for a World Model'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='121d9e85-0109-44ef-9976-b30e2df23688', metadata={'title': 'Probing LLMs for a World Model', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.', 'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'language': 'en'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='8539c230-32a2-4a01-b664-381c88574df0', metadata={'title': 'Probing LLMs for a World Model', 'language': 'en', 'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in')], 'times_transformed': 1, 'web_search': 'Yes'}\n",
      "---- GRADE DOCUMENTS ----\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "No relevant documents found.\n",
      "state {'documents': [], 'web_search': 'Yes', 'questions': 'What is few-shot learning in machine learning, and how does it work?', 'times_transformed': 1}\n",
      "---- DECIDE TO GENERATE ----\n",
      "time transformed: 1\n",
      "---Decicion: ALL documents are not relevant, need to transform query---\n",
      "Node 'grade_documents' output:\n",
      "Final Output:\n",
      "state {'questions': 'What is few-shot learning in machine learning, and how does it work?', 'documents': [], 'times_transformed': 1, 'web_search': 'Yes'}\n",
      "---- TRANSFORM QUERY ----\n",
      "updated times transformed: 2\n",
      "improved question: What is few-shot learning in machine learning, and what are the main techniques and applications of this approach?\n",
      "Node 'transform_query' output:\n",
      "Final Output:\n",
      "state {'questions': 'What is few-shot learning in machine learning, and what are the main techniques and applications of this approach?', 'documents': [], 'times_transformed': 2, 'web_search': 'Yes'}\n",
      "---- RETRIEVE ----\n",
      "Node 'retrieve' output:\n",
      "Final Output:\n",
      "state {'questions': 'What is few-shot learning in machine learning, and what are the main techniques and applications of this approach?', 'documents': [Document(id='1533ff1b-3cbb-4fbc-bd8d-abfa0e6305c6', metadata={'language': 'en', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.', 'title': 'Probing LLMs for a World Model', 'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='121d9e85-0109-44ef-9976-b30e2df23688', metadata={'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'title': 'Probing LLMs for a World Model', 'language': 'en', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='95640b43-35fb-4553-9c66-07d97ba79cd3', metadata={'title': 'Probing LLMs for a World Model', 'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.', 'language': 'en'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in'), Document(id='8539c230-32a2-4a01-b664-381c88574df0', metadata={'source': 'https://ai-office-hours.beehiiv.com/p/llm-probing', 'language': 'en', 'description': 'Using linear probes to dissect internal LLM embeddings to check for a hint of an internal world model.', 'title': 'Probing LLMs for a World Model'}, page_content='Probing LLMs for a World ModelAI Office HoursLoginSubscribe0AI Office HoursPostsProbing LLMs for a World ModelProbing LLMs for a World ModelSinan Ozdemir April 25, 2024  There are active debates over whether LLMs are just memorizing vast amounts of statistics or if they can learn a more cohesive representation of the world whose language they model. Some have found evidence for the latter by analyzing the learned representations of datasets and even go so far as to discover that LLMs can learn linear representations of space and time (arxiv.org/abs/2310.02207).  As part of the 2nd edition of my latest LLM book (coming out later this year) one idea I wanted to add as a net new section aimed at recreating some of the work done in this paper by looking at a dataset comes from a paper entitled “A cross-verified database of notable people, 3500 BC-2018 AD” claiming to build a “comprehensive and accurate database of notable individuals”; just what we need to probe some LLMs on their ability to retain information about notable individuals they read about on the web. I’m lucky to live in')], 'times_transformed': 2, 'web_search': 'Yes'}\n",
      "---- GRADE DOCUMENTS ----\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "No relevant documents found.\n",
      "state {'documents': [], 'web_search': 'Yes', 'questions': 'What is few-shot learning in machine learning, and what are the main techniques and applications of this approach?', 'times_transformed': 2}\n",
      "---- DECIDE TO GENERATE ----\n",
      "time transformed: 2\n",
      "Node 'grade_documents' output:\n",
      "Final Output:\n",
      "state {'questions': 'What is few-shot learning in machine learning, and what are the main techniques and applications of this approach?', 'documents': [], 'times_transformed': 2, 'web_search': 'Yes'}\n",
      "---- GENERATE ----\n",
      "Node 'generate' output:\n",
      "Final Output:\n",
      "Few-shot learning in machine learning refers to the ability of a model to learn new tasks or recognize new classes from only a small number of labeled examples. Main techniques include meta-learning (learning to learn), metric learning (comparing similarities), and data augmentation. Applications include image recognition, natural language processing, and medical diagnosis, where labeled data is scarce.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"questions\": \"What on earth is few shot learning?\",\"times_transformed\": 0}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}' output:\")\n",
    "    print(\"Final Output:\")\n",
    "print(value['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18f83994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- SET STATE ----\n",
      "Node 'set_state' output:\n",
      "Final Output:\n",
      "state {'questions': 'How to make good inputs to AI?', 'times_transformed': 0}\n",
      "---- RETRIEVE ----\n",
      "Node 'retrieve' output:\n",
      "Final Output:\n",
      "state {'questions': 'How to make good inputs to AI?', 'documents': [Document(id='1b057914-f092-42b1-931a-8fcbdd3227dc', metadata={'source': 'https://ai-office-hours.beehiiv.com/p/beyond-benchmarks', 'language': 'en', 'description': 'Evaluating AI and LLMs in the real world', 'title': 'Beyond Benchmarks'}, page_content='less meant for targeted adoption of AI and more meant to signal a turning point in AI: the heralding of Artificial General Intelligence (AGI) or Superintelligence - an AI going beyond human intelligence. To put it bluntly, even an AI scoring 100% on HLE would not\\xa0alone trigger a sense of AGI or Superintelligence to me. These high benchmark scores look impressive to us, the consumer, but they can stop reflecting true generalization of AI, exactly what Goodhart’s Law predicts. So what do we do? We will dive deeper into remedies for benchmarks in my live session and I plan to make a follow up post after the talk, but I’ll outline a few simple steps we can take now:  Use benchmarks to create a short list of models to evaluate - don’t use them to select a single model.  Make your own test sets - They are valid and frankly will tell you more than most public benchmarks will on your particular tasks.  Ask yourself, “who made this benchmark” and “what are they really trying to test?” Is it true reasoning beyond the knowledge an AI has, or simply the recall of a few facts that when put together, simulate'), Document(id='b0a6d169-fec3-46a9-b8bf-fda89e772891', metadata={'language': 'en', 'title': 'Beyond Benchmarks', 'source': 'https://ai-office-hours.beehiiv.com/p/beyond-benchmarks', 'description': 'Evaluating AI and LLMs in the real world'}, page_content='less meant for targeted adoption of AI and more meant to signal a turning point in AI: the heralding of Artificial General Intelligence (AGI) or Superintelligence - an AI going beyond human intelligence. To put it bluntly, even an AI scoring 100% on HLE would not\\xa0alone trigger a sense of AGI or Superintelligence to me. These high benchmark scores look impressive to us, the consumer, but they can stop reflecting true generalization of AI, exactly what Goodhart’s Law predicts. So what do we do? We will dive deeper into remedies for benchmarks in my live session and I plan to make a follow up post after the talk, but I’ll outline a few simple steps we can take now:  Use benchmarks to create a short list of models to evaluate - don’t use them to select a single model.  Make your own test sets - They are valid and frankly will tell you more than most public benchmarks will on your particular tasks.  Ask yourself, “who made this benchmark” and “what are they really trying to test?” Is it true reasoning beyond the knowledge an AI has, or simply the recall of a few facts that when put together, simulate'), Document(id='566673e0-cc20-4048-b8f0-7be9a1b6f02b', metadata={'title': 'Beyond Benchmarks', 'source': 'https://ai-office-hours.beehiiv.com/p/beyond-benchmarks', 'language': 'en', 'description': 'Evaluating AI and LLMs in the real world'}, page_content='less meant for targeted adoption of AI and more meant to signal a turning point in AI: the heralding of Artificial General Intelligence (AGI) or Superintelligence - an AI going beyond human intelligence. To put it bluntly, even an AI scoring 100% on HLE would not\\xa0alone trigger a sense of AGI or Superintelligence to me. These high benchmark scores look impressive to us, the consumer, but they can stop reflecting true generalization of AI, exactly what Goodhart’s Law predicts. So what do we do? We will dive deeper into remedies for benchmarks in my live session and I plan to make a follow up post after the talk, but I’ll outline a few simple steps we can take now:  Use benchmarks to create a short list of models to evaluate - don’t use them to select a single model.  Make your own test sets - They are valid and frankly will tell you more than most public benchmarks will on your particular tasks.  Ask yourself, “who made this benchmark” and “what are they really trying to test?” Is it true reasoning beyond the knowledge an AI has, or simply the recall of a few facts that when put together, simulate'), Document(id='8adb9f26-5dcd-421a-98c9-1eb00f57173a', metadata={'title': 'Beyond Benchmarks', 'source': 'https://ai-office-hours.beehiiv.com/p/beyond-benchmarks', 'description': 'Evaluating AI and LLMs in the real world', 'language': 'en'}, page_content='less meant for targeted adoption of AI and more meant to signal a turning point in AI: the heralding of Artificial General Intelligence (AGI) or Superintelligence - an AI going beyond human intelligence. To put it bluntly, even an AI scoring 100% on HLE would not\\xa0alone trigger a sense of AGI or Superintelligence to me. These high benchmark scores look impressive to us, the consumer, but they can stop reflecting true generalization of AI, exactly what Goodhart’s Law predicts. So what do we do? We will dive deeper into remedies for benchmarks in my live session and I plan to make a follow up post after the talk, but I’ll outline a few simple steps we can take now:  Use benchmarks to create a short list of models to evaluate - don’t use them to select a single model.  Make your own test sets - They are valid and frankly will tell you more than most public benchmarks will on your particular tasks.  Ask yourself, “who made this benchmark” and “what are they really trying to test?” Is it true reasoning beyond the knowledge an AI has, or simply the recall of a few facts that when put together, simulate')], 'times_transformed': 0}\n",
      "---- GRADE DOCUMENTS ----\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "No relevant documents found.\n",
      "state {'documents': [], 'web_search': 'Yes', 'questions': 'How to make good inputs to AI?', 'times_transformed': 0}\n",
      "---- DECIDE TO GENERATE ----\n",
      "time transformed: 0\n",
      "---Decicion: ALL documents are not relevant, need to transform query---\n",
      "Node 'grade_documents' output:\n",
      "Final Output:\n",
      "state {'questions': 'How to make good inputs to AI?', 'documents': [], 'times_transformed': 0, 'web_search': 'Yes'}\n",
      "---- TRANSFORM QUERY ----\n",
      "updated times transformed: 1\n",
      "improved question: What are the best practices for creating effective prompts or inputs for AI models?\n",
      "Node 'transform_query' output:\n",
      "Final Output:\n",
      "state {'questions': 'What are the best practices for creating effective prompts or inputs for AI models?', 'documents': [], 'times_transformed': 1, 'web_search': 'Yes'}\n",
      "---- RETRIEVE ----\n",
      "Node 'retrieve' output:\n",
      "Final Output:\n",
      "state {'questions': 'What are the best practices for creating effective prompts or inputs for AI models?', 'documents': [Document(id='4593f8e1-36a4-4fa0-b352-d80bcf42a710', metadata={'title': '(Re-) Ranking RAG Solutions', 'language': 'en', 'description': 'How only 5 lines of code can transform your RAG pipeline forever.', 'source': 'https://ai-office-hours.beehiiv.com/p/re-ranking-rag'}, page_content='point here is that I will be using the below prompt to generate test data but I cannot actually read the non-english examples and vet them myself so I am taking the questions generated by GPT-4 here with a grain of salt. I am designing a chatbot to use this document as information to our users.'), Document(id='aa898dbe-7d35-4652-bcca-6745a422b20d', metadata={'language': 'en', 'description': 'How only 5 lines of code can transform your RAG pipeline forever.', 'source': 'https://ai-office-hours.beehiiv.com/p/re-ranking-rag', 'title': '(Re-) Ranking RAG Solutions'}, page_content='point here is that I will be using the below prompt to generate test data but I cannot actually read the non-english examples and vet them myself so I am taking the questions generated by GPT-4 here with a grain of salt. I am designing a chatbot to use this document as information to our users.'), Document(id='76f26629-09e8-4655-8e7b-534187877581', metadata={'source': 'https://ai-office-hours.beehiiv.com/p/re-ranking-rag', 'description': 'How only 5 lines of code can transform your RAG pipeline forever.', 'language': 'en', 'title': '(Re-) Ranking RAG Solutions'}, page_content='point here is that I will be using the below prompt to generate test data but I cannot actually read the non-english examples and vet them myself so I am taking the questions generated by GPT-4 here with a grain of salt. I am designing a chatbot to use this document as information to our users.'), Document(id='a6adc957-2886-4837-aa61-2d876353b37c', metadata={'description': 'How only 5 lines of code can transform your RAG pipeline forever.', 'title': '(Re-) Ranking RAG Solutions', 'language': 'en', 'source': 'https://ai-office-hours.beehiiv.com/p/re-ranking-rag'}, page_content='point here is that I will be using the below prompt to generate test data but I cannot actually read the non-english examples and vet them myself so I am taking the questions generated by GPT-4 here with a grain of salt. I am designing a chatbot to use this document as information to our users.')], 'times_transformed': 1, 'web_search': 'Yes'}\n",
      "---- GRADE DOCUMENTS ----\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "No relevant documents found.\n",
      "state {'documents': [], 'web_search': 'Yes', 'questions': 'What are the best practices for creating effective prompts or inputs for AI models?', 'times_transformed': 1}\n",
      "---- DECIDE TO GENERATE ----\n",
      "time transformed: 1\n",
      "---Decicion: ALL documents are not relevant, need to transform query---\n",
      "Node 'grade_documents' output:\n",
      "Final Output:\n",
      "state {'questions': 'What are the best practices for creating effective prompts or inputs for AI models?', 'documents': [], 'times_transformed': 1, 'web_search': 'Yes'}\n",
      "---- TRANSFORM QUERY ----\n",
      "updated times transformed: 2\n",
      "improved question: What are the most effective strategies and best practices for designing high-quality prompts for AI language models?\n",
      "Node 'transform_query' output:\n",
      "Final Output:\n",
      "state {'questions': 'What are the most effective strategies and best practices for designing high-quality prompts for AI language models?', 'documents': [], 'times_transformed': 2, 'web_search': 'Yes'}\n",
      "---- RETRIEVE ----\n",
      "Node 'retrieve' output:\n",
      "Final Output:\n",
      "state {'questions': 'What are the most effective strategies and best practices for designing high-quality prompts for AI language models?', 'documents': [Document(id='4593f8e1-36a4-4fa0-b352-d80bcf42a710', metadata={'language': 'en', 'title': '(Re-) Ranking RAG Solutions', 'source': 'https://ai-office-hours.beehiiv.com/p/re-ranking-rag', 'description': 'How only 5 lines of code can transform your RAG pipeline forever.'}, page_content='point here is that I will be using the below prompt to generate test data but I cannot actually read the non-english examples and vet them myself so I am taking the questions generated by GPT-4 here with a grain of salt. I am designing a chatbot to use this document as information to our users.'), Document(id='aa898dbe-7d35-4652-bcca-6745a422b20d', metadata={'source': 'https://ai-office-hours.beehiiv.com/p/re-ranking-rag', 'language': 'en', 'description': 'How only 5 lines of code can transform your RAG pipeline forever.', 'title': '(Re-) Ranking RAG Solutions'}, page_content='point here is that I will be using the below prompt to generate test data but I cannot actually read the non-english examples and vet them myself so I am taking the questions generated by GPT-4 here with a grain of salt. I am designing a chatbot to use this document as information to our users.'), Document(id='76f26629-09e8-4655-8e7b-534187877581', metadata={'description': 'How only 5 lines of code can transform your RAG pipeline forever.', 'language': 'en', 'title': '(Re-) Ranking RAG Solutions', 'source': 'https://ai-office-hours.beehiiv.com/p/re-ranking-rag'}, page_content='point here is that I will be using the below prompt to generate test data but I cannot actually read the non-english examples and vet them myself so I am taking the questions generated by GPT-4 here with a grain of salt. I am designing a chatbot to use this document as information to our users.'), Document(id='a6adc957-2886-4837-aa61-2d876353b37c', metadata={'title': '(Re-) Ranking RAG Solutions', 'description': 'How only 5 lines of code can transform your RAG pipeline forever.', 'source': 'https://ai-office-hours.beehiiv.com/p/re-ranking-rag', 'language': 'en'}, page_content='point here is that I will be using the below prompt to generate test data but I cannot actually read the non-english examples and vet them myself so I am taking the questions generated by GPT-4 here with a grain of salt. I am designing a chatbot to use this document as information to our users.')], 'times_transformed': 2, 'web_search': 'Yes'}\n",
      "---- GRADE DOCUMENTS ----\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "No relevant documents found.\n",
      "state {'documents': [], 'web_search': 'Yes', 'questions': 'What are the most effective strategies and best practices for designing high-quality prompts for AI language models?', 'times_transformed': 2}\n",
      "---- DECIDE TO GENERATE ----\n",
      "time transformed: 2\n",
      "Node 'grade_documents' output:\n",
      "Final Output:\n",
      "state {'questions': 'What are the most effective strategies and best practices for designing high-quality prompts for AI language models?', 'documents': [], 'times_transformed': 2, 'web_search': 'Yes'}\n",
      "---- GENERATE ----\n",
      "Node 'generate' output:\n",
      "Final Output:\n",
      "The most effective strategies for designing high-quality prompts for AI language models include being clear and specific about the desired output, providing sufficient context or examples, and using structured formats (such as bullet points or numbered lists) when appropriate. Best practices also involve avoiding ambiguity, testing and iterating prompts to refine results, and tailoring the prompt to the model’s capabilities and limitations. These approaches help ensure more accurate, relevant, and useful responses from the AI.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"questions\": \"How to make good inputs to AI?\",\"times_transformed\": 0}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}' output:\")\n",
    "    print(\"Final Output:\")\n",
    "print(value['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae1127",
   "metadata": {},
   "source": [
    "### Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd57b5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualize our graph\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09eeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a038eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
